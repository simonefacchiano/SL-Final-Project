{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProfAIling project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries.\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from spacy import tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "tkz = tokenizer.Tokenizer(nlp.vocab)\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import unicodedata\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ooh shiny new commenting!</td>\n",
       "      <td>16</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so wuts up? today i had the parade. suked. but...</td>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i don't know about anyone else anymore, but i'...</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urlLink    another roof-top sunset  Posted by ...</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gawd i luv my nanny!  she's absolutely the gre...</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526807</th>\n",
       "      <td>\"Write injuries in sand, kindnesses in marble....</td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526808</th>\n",
       "      <td>urlLink    Wes and his Dad Stan  urlLink</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526809</th>\n",
       "      <td>I also prefer calling you a nice guy.  In fact...</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526810</th>\n",
       "      <td>Angela and I went to see Othello last night. I...</td>\n",
       "      <td>17</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526811</th>\n",
       "      <td>I am just keeping it short today because I am ...</td>\n",
       "      <td>33</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526812 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  age  gender\n",
       "0                               ooh shiny new commenting!   16  female\n",
       "1       so wuts up? today i had the parade. suked. but...   14    male\n",
       "2       i don't know about anyone else anymore, but i'...   24  female\n",
       "3       urlLink    another roof-top sunset  Posted by ...   24    male\n",
       "4       gawd i luv my nanny!  she's absolutely the gre...   23  female\n",
       "...                                                   ...  ...     ...\n",
       "526807  \"Write injuries in sand, kindnesses in marble....   34    male\n",
       "526808           urlLink    Wes and his Dad Stan  urlLink   24  female\n",
       "526809  I also prefer calling you a nice guy.  In fact...   13    male\n",
       "526810  Angela and I went to see Othello last night. I...   17  female\n",
       "526811  I am just keeping it short today because I am ...   33  female\n",
       "\n",
       "[526812 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data.\n",
    "train = pd.read_json('/Users/simonefacchiano/Desktop/Data Science/SL/Project/SL-Final-Project/train.json')\n",
    "\n",
    "# Let's have a look at our data.\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (do not run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Counts and lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column for the length of the posts.\n",
    "train['length'] = train['post'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'M DELETING PART OF THE DATA, NEED TO BE DISCUSS!!\n",
    "train = train.loc[train[\"length\"]<80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to eliminate post with this length\n",
    "fig = px.histogram(train, \n",
    "                   x='length',\n",
    "                   title='Histogram of Packet Length',\n",
    "                   opacity=0.8,\n",
    "                   width=800, \n",
    "                   height=400)\n",
    "fig.update_layout(title_text=\"Length\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missin values.\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target class distribution.\n",
    "#train.age.hist(bins = 15,  color = \"#118ab2\", ec=\"white\", label = \"Age distribution\")\n",
    "fig = px.histogram(train, \n",
    "                   x='age',\n",
    "                   title='Age distribution',\n",
    "                   opacity=0.8,\n",
    "                   width=800, \n",
    "                   height=400,\n",
    "                   color_discrete_sequence = [our_col[0]],\n",
    "                   )\n",
    "fig.update_layout(\n",
    "    yaxis_title_text='Frequency',\n",
    "    bargap=0.01, # gap between bars of adjacent location coordinates\n",
    "    #margin=dict(l=20, r=20, t=20, b=20),\n",
    "    #paper_bgcolor=\"gray\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Check\n",
    "train['age_class'] = pd.cut(\n",
    "        train[\"age\"],\n",
    "        bins=[12, 18, 28, 50],\n",
    "        labels=[0, 1, 2]\n",
    "    ).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train[train.age <= 17]))                        # Class 1\n",
    "print(len(train[(train.age >= 23) & (train.age <= 27)]))  # Class 2\n",
    "print(len(train[(train.age >= 28) & (train.age <= 48)]))  # Class 3\n",
    "\n",
    "#same check\n",
    "train[\"age_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new colums with the number of word for the number of words in every post.\n",
    "# Different from Lenght because is not the numbers of characters.\n",
    "train['word_count'] = train['post'].apply(lambda x: len(str(x).split()))\n",
    "print(train[train['age_class']==0]['word_count'].mean()) # 12 - 17 tweets\n",
    "print(train[train['age_class']==1]['word_count'].mean()) # 18 - 29 tweets\n",
    "print(train[train['age_class']==2]['word_count'].mean()) # 29 - 50 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This histograms are only up to 1500 words because few tweets have more than this number but there are some tweet with a loooots of words.\n",
    "train[train.age_class==0]['word_count'].max() #115370 \n",
    "train[train.age_class==1]['word_count'].max() #69208\n",
    "train[train.age_class==2]['word_count'].max() #131169\n",
    "\n",
    "#weeeel very big, maybe they are outliers...\n",
    "word_0 = px.histogram(train[train.age_class==0][train.word_count < 1500]['word_count'],opacity=0.8,color_discrete_sequence = [our_col[0]],nbins=15)\n",
    "word_1 = px.histogram(train[train.age_class==1][train.word_count < 1500]['word_count'],opacity=0.8,color_discrete_sequence = [our_col[1]],nbins=15)\n",
    "word_2 = px.histogram(train[train.age_class==2][train.word_count < 1500]['word_count'],opacity=0.8,color_discrete_sequence = [our_col[2]],nbins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=3,subplot_titles=(\"Class 1\", \"Class 2\", \"Class 3\"),shared_yaxes=True)\n",
    "fig.add_trace(word_0['data'][0], row=1, col=1)\n",
    "fig.add_trace(word_1['data'][0], row=1, col=2)\n",
    "fig.add_trace(word_2['data'][0], row=1, col=3)\n",
    "fig.update_layout(template='ggplot2',bargap=0.1,showlegend=False, height = 400, width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence counts\n",
    "train[\"sent_count\"] = train[\"post\"].map(lambda x: len(sent_tokenize(x)))\n",
    "# Average word length\n",
    "train[\"avg_word_len\"] = train[\"post\"].map(lambda x: np.mean([len(w) for w in str(x).split()])).fillna(0)\n",
    "# Average sentence length\n",
    "train[\"avg_sent_len\"] = train[\"post\"].map(lambda x: np.mean([len(w.split()) for w in sent_tokenize(x)])).fillna(0)\n",
    "\n",
    "#take ages to run (8 minutes ahahah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small = train.loc[train[\"length\"]<1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_labels = [\"Class0\",\"Class1\",\"Class2\"]\n",
    "x1_length = train_small[train_small.age_class==0]['length']\n",
    "x2_length = train_small[train_small.age_class==1]['length']\n",
    "x3_length = train_small[train_small.age_class==2]['length']\n",
    "hist_data_length = [x1_length,x2_length,x3_length]\n",
    "\n",
    "x1_word = train_small[train_small.age_class==0][train_small.word_count <= 230]['word_count']\n",
    "x2_word = train_small[train_small.age_class==1][train_small.word_count <= 230]['word_count']\n",
    "x3_word = train_small[train_small.age_class==2][train_small.word_count <= 230]['word_count']\n",
    "hist_data_word = [x1_word,x2_word,x3_word]\n",
    "\n",
    "x1_sent = train_small[train_small.age_class==0][train_small.sent_count <= 30]['sent_count']\n",
    "x2_sent = train_small[train_small.age_class==1][train_small.sent_count <= 30]['sent_count']\n",
    "x3_sent = train_small[train_small.age_class==2][train_small.sent_count <= 30]['sent_count']\n",
    "hist_data_sent = [x1_sent,x2_sent,x3_sent]\n",
    "\n",
    "\n",
    "x1_avg_w = train_small[train_small.age_class==0][train_small.avg_word_len <= 10]['avg_word_len']\n",
    "x2_avg_w = train_small[train_small.age_class==1][train_small.avg_word_len <= 10]['avg_word_len']\n",
    "x3_avg_w = train_small[train_small.age_class==2][train_small.avg_word_len <= 10]['avg_word_len']\n",
    "hist_data_avg_w = [x1_avg_w,x2_avg_w,x3_avg_w]\n",
    "\n",
    "x1_avg_s = train_small[train_small.age_class==0][train_small.avg_sent_len <= 50]['avg_sent_len']\n",
    "x2_avg_s = train_small[train_small.age_class==1][train_small.avg_sent_len <= 50]['avg_sent_len']\n",
    "x3_avg_s = train_small[train_small.age_class==2][train_small.avg_sent_len <= 50]['avg_sent_len']\n",
    "hist_data_avg_s = [x1_avg_s,x2_avg_s,x3_avg_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = ff.create_distplot(hist_data_length, group_labels,show_hist=False, show_rug= False,colors=our_col,show_curve= True)\n",
    "word = ff.create_distplot(hist_data_word, group_labels,show_hist=False, show_rug= False,colors=our_col,show_curve= True)\n",
    "sent = ff.create_distplot(hist_data_sent, group_labels,show_hist=False, show_rug= False,colors=our_col,show_curve= True)\n",
    "avg_word = ff.create_distplot(hist_data_avg_w, group_labels,show_hist=False, show_rug= False,colors=our_col,show_curve= True)\n",
    "avg_sent = ff.create_distplot(hist_data_avg_s, group_labels,show_hist=False, show_rug= False,colors=our_col,show_curve= True)\n",
    "age = ff.create_distplot([train_small.age], group_labels=[\"Age\"],show_hist=False, show_rug= False,colors=[our_col[3]],show_curve= True)\n",
    "\n",
    "#60 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to avoid too many legends\n",
    "length['data'][0]['showlegend'] = False\n",
    "word['data'][0]['showlegend'] = False\n",
    "sent['data'][0]['showlegend'] = False\n",
    "avg_word['data'][0]['showlegend'] = False\n",
    "\n",
    "length['data'][1]['showlegend'] = False\n",
    "word['data'][1]['showlegend'] = False\n",
    "sent['data'][1]['showlegend'] = False\n",
    "avg_word['data'][1]['showlegend'] = False\n",
    "\n",
    "length['data'][2]['showlegend'] = False\n",
    "word['data'][2]['showlegend'] = False\n",
    "sent['data'][2]['showlegend'] = False\n",
    "avg_word['data'][2]['showlegend'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = make_subplots(rows=2, cols=3,subplot_titles=(\"Age\", \"Word Count\", \"Sentence Count\", \"Avg word lenght\", \"Avg Sentence length\",\"Length\"))\n",
    "kde.add_trace(length['data'][0], row=2, col=3)\n",
    "kde.add_trace(length['data'][1], row=2, col=3)\n",
    "kde.add_trace(length['data'][2], row=2, col=3)\n",
    "\n",
    "kde.add_trace(word['data'][0], row=1, col=2)\n",
    "kde.add_trace(word['data'][1], row=1, col=2)\n",
    "kde.add_trace(word['data'][2], row=1, col=2)\n",
    "\n",
    "kde.add_trace(sent['data'][0], row=1, col=3)\n",
    "kde.add_trace(sent['data'][1], row=1, col=3)\n",
    "kde.add_trace(sent['data'][2], row=1, col=3)\n",
    "\n",
    "kde.add_trace(avg_word['data'][0], row=2, col=1)\n",
    "kde.add_trace(avg_word['data'][1], row=2, col=1)\n",
    "kde.add_trace(avg_word['data'][2], row=2, col=1)\n",
    "\n",
    "kde.add_trace(avg_sent['data'][0], row=2, col=2)\n",
    "kde.add_trace(avg_sent['data'][1], row=2, col=2)\n",
    "kde.add_trace(avg_sent['data'][2], row=2, col=2)\n",
    "kde.add_trace(age['data'][0], row=1, col=1)\n",
    "kde.update_layout(template='ggplot2')\n",
    "kde.update_layout(\n",
    "    height=1000, \n",
    "    width=1400,\n",
    "    title_text=\"KDE of the variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small_word_count = train_small[train_small.word_count <= 230]\n",
    "train_small_sent_count = train_small[train_small.sent_count <= 30]\n",
    "train_small_avg_word = train_small[train_small.avg_word_len <= 10]\n",
    "train_small_avg_sent = train_small[train_small.avg_sent_len <= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small_word_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE plot\n",
    "# (Kernel density estimate)\n",
    "# KDE represents the data using a continuous probability density curve in one or more dimensions.\n",
    "\n",
    "#could be cool but we need to remove outliers... \n",
    "#sns.kdeplot(data = train, x = \"length\", hue = \"age_class\")\n",
    "fig, axes = plt.subplots(figsize=(17,10), ncols=3, nrows=2)\n",
    "sns.kdeplot(data = train_small, x = \"age\", ax = axes[0][0], label = \"Age\", color = our_col[0])\n",
    "sns.kdeplot(data = train_small, x = \"length\", ax = axes[0][1], label = \"Length\", hue=\"age_class\", palette = our_col)\n",
    "sns.kdeplot(data = train_small_word_count, x = \"word_count\", ax = axes[0][2], label = \"Word Count\", hue=\"age_class\", palette = our_col)\n",
    "sns.kdeplot(data = train_small_avg_sent, x = \"avg_sent_len\", ax = axes[1][0], label = \"Average sentence length\", hue=\"age_class\", palette = our_col)\n",
    "sns.kdeplot(data = train_small_avg_word, x = \"avg_word_len\", ax = axes[1][1], label = \"Average word length\", hue=\"age_class\", palette = our_col)\n",
    "sns.kdeplot(data = train_small_sent_count, x = \"sent_count\", ax = axes[1][2], label = \"Sentence count\", hue=\"age_class\", palette = our_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for the variables or violinplots\n",
    "\n",
    "#Ora non c'ho voglia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing | Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before doing anything, we save the original colum of posts in a specifi object that we will keep.\n",
    "original_posts = train['post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ooh shiny new commenting!</td>\n",
       "      <td>16</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so wuts up? today i had the parade. suked. but...</td>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i don't know about anyone else anymore, but i'...</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urlLink    another roof-top sunset  Posted by ...</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gawd i luv my nanny!  she's absolutely the gre...</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526807</th>\n",
       "      <td>\"Write injuries in sand, kindnesses in marble....</td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526808</th>\n",
       "      <td>urlLink    Wes and his Dad Stan  urlLink</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526809</th>\n",
       "      <td>I also prefer calling you a nice guy.  In fact...</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526810</th>\n",
       "      <td>Angela and I went to see Othello last night. I...</td>\n",
       "      <td>17</td>\n",
       "      <td>female</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526811</th>\n",
       "      <td>I am just keeping it short today because I am ...</td>\n",
       "      <td>33</td>\n",
       "      <td>female</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526812 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  age  gender  length\n",
       "0                               ooh shiny new commenting!   16  female       4\n",
       "1       so wuts up? today i had the parade. suked. but...   14    male      48\n",
       "2       i don't know about anyone else anymore, but i'...   24  female      80\n",
       "3       urlLink    another roof-top sunset  Posted by ...   24    male       7\n",
       "4       gawd i luv my nanny!  she's absolutely the gre...   23  female     730\n",
       "...                                                   ...  ...     ...     ...\n",
       "526807  \"Write injuries in sand, kindnesses in marble....   34    male      16\n",
       "526808           urlLink    Wes and his Dad Stan  urlLink   24  female       7\n",
       "526809  I also prefer calling you a nice guy.  In fact...   13    male     152\n",
       "526810  Angela and I went to see Othello last night. I...   17  female      77\n",
       "526811  I am just keeping it short today because I am ...   33  female     196\n",
       "\n",
       "[526812 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We also save the original length of the posts... you never know...\n",
    "\n",
    "def post_length(text):\n",
    "    return len(text.split())\n",
    "\n",
    "train['length'] = train['post'].apply(post_length) \n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0. Expand Contractions\n",
    "\n",
    "We noticed that it is better to expand the contractions at the begginning, before lowering the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/text-normalization-for-natural-language-processing-nlp-70a314bfa646\n",
    "# Not as efficient as other specialized packets... bu at least it works well\n",
    "contractions_dict = {\"ain't\": \"are not\", \"'s\":\" \", \" s \":\" is\", \"aren't\": \"are not\", \"Aren't\": \"are not\", \"Can't\": \"can not\", \"can't\": \"can not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"don t\": \"do not\", \"dont\": \"do not\", \"dunno\": \"do not know\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \" hes \": \" he is \", \"he'll've\": \"he will have\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"i'll\": \"i will\", \"'ll\":\" will\", \"I'll've\": \"I will have\", \"I’m\": \"I am\", \"i'm\": \"i am\", \"'m\": \" am\", \" im \": \" i am \", \"I've\": \"I have\", \"i've\": \"i have\", \"I've\": \"I have\", \"havent\": \"have not\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll’ve\": \"it will have\", \"let's\": \"let us\", \"lets\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't’ve\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"She'll\": \"she will\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"they'd\": \"they would\", \"they'd've\": \"they would have\",\"they'll\": \"they will\", \"wont\": \"will not\",\n",
    "  \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what've\": \"what have\", \"when've\": \"when have\", \"where’d\": \"where did\", \"where've\": \"where have\",\n",
    "  \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who've\": \"who have\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y’all\": \"you all\", \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"You'll\": \"you will\", \"you'll've\": \"you will have\", \"You're\": \"you are\", \"you're\": \"you are\", \"you've\": \"you have\", \"wanna\": \"want to\", \" u \": \" you \", \" r \": \" are \", \"gawd\": \"god\", \"urlLink\": \"\", \"luv\": \"love\", \"Luv\": \"Love\", \"wuts\": \"what is\", \"wasnt\": \"was not\", \"Wasnt\": \"was not\", \" bday \": \"birthday\", \" gotta \": \"got to\", \"gonna\": \"going to\",\n",
    "  \"nvr\": \"never\", \" cuz \": \" because \", \" cos \": \" because \",\" cant \": \" can not \", \"yr\": \" years old\", \"i\\'d\": \"i\\ would\", \"they\\'d\": \"they\\ would\", \"we\\'re\": \"we\\ are\", \"shouldn\\'t\": \"should\\ not\", \"Don\\'t\": \"Do\\ not\", \"won\\'t\": \"will\\ not\", \"haven\\'t\": \"have\\ not\", \"you\\'re\": \"you\\ are\", \"they\\'re\": \"they\\ are\", \"Didn\\'t\": \"Did\\ not\", \"Hasn\\'t\": \"Has\\ not\", \"I\\'d\": \"I\\ would\", \"you\\'ve\": \"you\\ have\", \"peeps\": \"people\", \"it's\": \"it is\", \"kinda\": \"kind of\", \"buyin\": \"buying\", \"Its\": \"It is\", \"bout\": \"about\", \" ppl \": \" people \", \" n \": \" and \", \"enuf\": \"enough\", \"btw\": \"by the way\", \"BTW\": \"BY THE WAY\", 'b/c': \"because\", \" aabout\": \"about\", \" aaabout\": \"about\", \"aaaabout\": \"about\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_re = re.compile('(%s)'%'|'.join(contractions_dict.keys()))\n",
    "\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "  def replace(match):\n",
    "    return contractions_dict[match.group(0)]\n",
    "  return contractions_re.sub(replace, s)\n",
    "\n",
    "train['post'] = train.post.apply(expand_contractions)\n",
    "\n",
    "# 5m 50s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Convert to Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowering(text):\n",
    "    return text.lower()\n",
    "\n",
    "train['post'] = train.post.apply(lowering)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Remove URLs and HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10698"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First of all... do we really have any URL? Let's check:\n",
    "len(train[train.post.str.contains('http')]) # 10 thousands posts contain reference to websites. We need to remove these websites from the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    return re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "train['post'] = train.post.apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "print(len(train[train.post.str.contains('href=')])) # Only 88.. we can drop them\n",
    "\n",
    "def remove_html_tags_func(text):\n",
    "    return BeautifulSoup(text, 'html.parser').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Remove strange accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "train['post'] = train.post.apply(remove_accents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Remove Punctuation (and Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # return re.sub(r'[^a-zA-Z0-9]', ' ', text) # --> if you allow for numbers\n",
    "    return re.sub(r'[^a-zA-Z]', ' ', text) # --> if you do not allow for numbers\n",
    "\n",
    "train['post'] = train.post.apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Remove extra whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'^\\s*|\\s\\s*', ' ', text).strip()\n",
    "\n",
    "train['post'] = train.post.apply(remove_extra_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Before going on... delete rows containing 0 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ooh shiny new commenting</td>\n",
       "      <td>16</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so what is up today i had the parade suked but...</td>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i do not know aabout anyone else anymore but i...</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>another roof top sunset posted by paul</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>god i love my nanny she absolutely the greates...</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526807</th>\n",
       "      <td>write injuries in sand kindnesses in marble fr...</td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526808</th>\n",
       "      <td>wes and his dad stan</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526809</th>\n",
       "      <td>i also prefer calling you a nice guy in fact t...</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526810</th>\n",
       "      <td>angela and i went to see othello last night it...</td>\n",
       "      <td>17</td>\n",
       "      <td>female</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526811</th>\n",
       "      <td>i am just keeping it short today because i am ...</td>\n",
       "      <td>33</td>\n",
       "      <td>female</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526812 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  age  gender  length\n",
       "0                                ooh shiny new commenting   16  female       4\n",
       "1       so what is up today i had the parade suked but...   14    male      48\n",
       "2       i do not know aabout anyone else anymore but i...   24  female      80\n",
       "3                  another roof top sunset posted by paul   24    male       7\n",
       "4       god i love my nanny she absolutely the greates...   23  female     730\n",
       "...                                                   ...  ...     ...     ...\n",
       "526807  write injuries in sand kindnesses in marble fr...   34    male      16\n",
       "526808                               wes and his dad stan   24  female       7\n",
       "526809  i also prefer calling you a nice guy in fact t...   13    male     152\n",
       "526810  angela and i went to see othello last night it...   17  female      77\n",
       "526811  i am just keeping it short today because i am ...   33  female     196\n",
       "\n",
       "[526812 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.post != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Remove non english posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "es\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# Sample usage:\n",
    "sample_en = train.iloc[789].post  # <-- example of english post\n",
    "print(detect(sample_en))\n",
    "\n",
    "sample_sp = train.iloc[491204].post  # <-- example of spanish post\n",
    "print(detect(sample_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'news marine who vanished says he did not desert marine who vanished says he did not desert this is a rather peculiar story i wonderabout it it saddens me that because he is an arab american there is additional concern about this story but it is part of the times in which we live in'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[21].post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17612"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list to store the row numbers where language is 'es'\n",
    "rows_to_delete = []\n",
    "\n",
    "# Iterate over each row in the dataset\n",
    "for index, row in train.iterrows():\n",
    "    post = row['post']\n",
    "\n",
    "    det = detect(post)\n",
    "    \n",
    "    if det != 'en':\n",
    "        rows_to_delete.append(index)\n",
    "\n",
    "len(rows_to_delete)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salviamo la lista\n",
    "with open(\"non_english_rows.pickle\", \"wb\") as file:\n",
    "    pickle.dump(rows_to_delete, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/simonefacchiano/Desktop/Data Science/SL/Project/non_english_rows.pickle\", \"rb\") as file:\n",
    "    rows_to_delete = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ooh shiny new commenting</td>\n",
       "      <td>16</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so what is up today i had the parade suked but...</td>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i do not know aabout anyone else anymore but i...</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>another roof top sunset posted by paul</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>god i love my nanny she absolutely the greates...</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526807</th>\n",
       "      <td>write injuries in sand kindnesses in marble fr...</td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526808</th>\n",
       "      <td>wes and his dad stan</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526809</th>\n",
       "      <td>i also prefer calling you a nice guy in fact t...</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526810</th>\n",
       "      <td>angela and i went to see othello last night it...</td>\n",
       "      <td>17</td>\n",
       "      <td>female</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526811</th>\n",
       "      <td>i am just keeping it short today because i am ...</td>\n",
       "      <td>33</td>\n",
       "      <td>female</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503900 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  age  gender  length\n",
       "0                                ooh shiny new commenting   16  female       4\n",
       "1       so what is up today i had the parade suked but...   14    male      48\n",
       "2       i do not know aabout anyone else anymore but i...   24  female      80\n",
       "3                  another roof top sunset posted by paul   24    male       7\n",
       "4       god i love my nanny she absolutely the greates...   23  female     730\n",
       "...                                                   ...  ...     ...     ...\n",
       "526807  write injuries in sand kindnesses in marble fr...   34    male      16\n",
       "526808                               wes and his dad stan   24  female       7\n",
       "526809  i also prefer calling you a nice guy in fact t...   13    male     152\n",
       "526810  angela and i went to see othello last night it...   17  female      77\n",
       "526811  i am just keeping it short today because i am ...   33  female     196\n",
       "\n",
       "[503900 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(rows_to_delete)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Delete Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prima opzione: 179 parole vietate\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# sw_nltk = stopwords.words('english')\n",
    "\n",
    "# Seconda opzione: 326\n",
    "import spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "sw_spacy = en.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete stop words\n",
    "def delete_stopwords(text):\n",
    "    words = [word for word in text.split() if word.lower() not in sw_spacy]\n",
    "    new_text = \" \".join(words)\n",
    "    return new_text\n",
    "\n",
    "# Create new columns with new text and new length\n",
    "train['post'] = train['post'].apply(delete_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ooh shiny new commenting</td>\n",
       "      <td>16</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today parade suked bad band year battle today ...</td>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know aabout anymore concerned everyday want bo...</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roof sunset posted paul</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>god love nanny absolutely greatest woman earth...</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526807</th>\n",
       "      <td>write injuries sand kindnesses marble french p...</td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526808</th>\n",
       "      <td>wes dad stan</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526809</th>\n",
       "      <td>prefer calling nice guy fact obviously carried...</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526810</th>\n",
       "      <td>angela went othello night great noah shaved he...</td>\n",
       "      <td>17</td>\n",
       "      <td>female</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526811</th>\n",
       "      <td>keeping short today busy wasting time ways onl...</td>\n",
       "      <td>33</td>\n",
       "      <td>female</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503900 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  age  gender  length\n",
       "0                                ooh shiny new commenting   16  female       4\n",
       "1       today parade suked bad band year battle today ...   14    male      48\n",
       "2       know aabout anymore concerned everyday want bo...   24  female      80\n",
       "3                                 roof sunset posted paul   24    male       7\n",
       "4       god love nanny absolutely greatest woman earth...   23  female     730\n",
       "...                                                   ...  ...     ...     ...\n",
       "526807  write injuries sand kindnesses marble french p...   34    male      16\n",
       "526808                                       wes dad stan   24  female       7\n",
       "526809  prefer calling nice guy fact obviously carried...   13    male     152\n",
       "526810  angela went othello night great noah shaved he...   17  female      77\n",
       "526811  keeping short today busy wasting time ways onl...   33  female     196\n",
       "\n",
       "[503900 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_clean_2.pickle\", \"wb\") as file:\n",
    "    pickle.dump(train, file)\n",
    "\n",
    "# Train con le nuove contraizoni, preprocessato e senza righe non inglesi    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But wait: maybe we need to remove other words\n",
    "### Most common words DA RISOLVERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "def most_common_words(train):\n",
    "    stop = set(stopwords.words(\"english\"))\n",
    "    corpus = [word for i in train[\"post\"].str.split().values.tolist() for word in i if (word not in stop)]\n",
    "    most_common = FreqDist(corpus).most_common(200)\n",
    "    words, frequency = [], []\n",
    "    for word, count in most_common:\n",
    "        words.append(word)\n",
    "        frequency.append(count)   \n",
    "    return dict(zip(words, frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'like': 435992,\n",
       " 'know': 285699,\n",
       " 'time': 285645,\n",
       " 'going': 232480,\n",
       " 'people': 229663,\n",
       " 'think': 216607,\n",
       " 'good': 215576,\n",
       " 'got': 207280,\n",
       " 'day': 191642,\n",
       " 'want': 176244,\n",
       " 'today': 154235,\n",
       " 'love': 150412,\n",
       " 'way': 148066,\n",
       " 'went': 146619,\n",
       " 'life': 135501,\n",
       " 'new': 133953,\n",
       " 'work': 131683,\n",
       " 'things': 130909,\n",
       " 'right': 127987,\n",
       " 'said': 119049,\n",
       " 'little': 118989,\n",
       " 'night': 118356,\n",
       " 'thing': 109681,\n",
       " 'feel': 106752,\n",
       " 'home': 105733,\n",
       " 'need': 100770,\n",
       " 'years': 89803,\n",
       " 'come': 88690,\n",
       " 'oh': 88007,\n",
       " 'long': 86845,\n",
       " 'ok': 55327,\n",
       " 'pm': 37974,\n",
       " 'th': 36700}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words(train)\n",
    "# Molte di queste parole vanno sicuramente eliminate. Altre, sono per esempio \"th\", \"pm\", \"oh\"... togliamo anche quelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(list(most_common_w.keys())[:30], list(most_common_w.values())[:30])\n",
    "plt.xlabel(\"Parole\")\n",
    "plt.ylabel(\"Frequenza\")\n",
    "plt.title(\"Barplot delle parole e delle relative frequenze\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_remove_1 = ['oh', 'ok', 'pm', 'th', ' e ', ' p ']\n",
    "words_to_remove_2 = list(most_common_w.keys())[:30]\n",
    "\n",
    "words_to_remove = words_to_remove_1 + words_to_remove_2\n",
    "\n",
    "# Delete other words\n",
    "def delete_other_words(text):\n",
    "    words = [word for word in text.split() if word.lower() in words_to_remove]\n",
    "    new_text = \" \".join(words)\n",
    "    return new_text\n",
    "\n",
    "# Create new columns with new text and new length\n",
    "train['post'] = train['post'].apply(delete_other_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ok!\n",
    "We can declare the preprocessinh phase completed.\n",
    "We can now compute the new length of the posts and have a look at the final result..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['new_length'] = train['post'].apply(post_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We save this dataset in a pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sample usage\n",
    "save_object(train, 'train_clean_no_spain.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, we will read this pickle object instead of running the whole code again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new</td>\n",
       "      <td>16</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today today little like</td>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>want got want thing want got way good little l...</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love know today time want know life little yea...</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526807</th>\n",
       "      <td></td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526808</th>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526809</th>\n",
       "      <td>home think know like night home right want</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526810</th>\n",
       "      <td>went night like people night</td>\n",
       "      <td>17</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526811</th>\n",
       "      <td>today time new like want</td>\n",
       "      <td>33</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  age  gender\n",
       "0                                                     new   16  female\n",
       "1                                 today today little like   14    male\n",
       "2       want got want thing want got way good little l...   24  female\n",
       "3                                                           24    male\n",
       "4       love know today time want know life little yea...   23  female\n",
       "...                                                   ...  ...     ...\n",
       "526807                                                      34    male\n",
       "526808                                                      24  female\n",
       "526809         home think know like night home right want   13    male\n",
       "526810                       went night like people night   17  female\n",
       "526811                           today time new like want   33  female\n",
       "\n",
       "[503900 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('/Users/simonefacchiano/Desktop/Data Science/SL/Project/train_clean_2.pkl')\n",
    "train = train[['post', 'age', 'gender']]\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PER SUSANNA: spostare/ eliminare questa seconda parte di EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How the length differs between males and females\n",
    "fig = px.histogram(train[train.length <= 1000], x=\"length\", color=\"gender\")\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diversa lunghezza prima e dopo il pre-processing\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=list(train[train.length < 1000].length)))\n",
    "fig.add_trace(go.Histogram(x=list(train[train.length < 1000].new_length)))\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding using Sentence Transformers\n",
    "\n",
    "Our main source of inspiration:\n",
    "https://www.youtube.com/watch?v=c7AqnswslWo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "\n",
    "# Pipeline that is tipically used:\n",
    "# -   Remove punctuation                       (done)\n",
    "# -   Remove stopwords                         (done)\n",
    "# -   Implement lemmatization and tokenization (TODO)\n",
    "\n",
    "# In our particular case, it seems that we have to do the following:\n",
    "# -   Lemmatize each row\n",
    "# -   Embed using sentence transformers\n",
    "\n",
    "# At the present stage, it should be easy to do.\n",
    "# So, first thing first, we need to tokenize and lemmatize every sentence we have. \n",
    "# After this opearation, we should have the same exact structure of the dataset, but this time the posts will be a little bit different because of the lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/models/en\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Let's create or tokenizer function\n",
    "\n",
    "def lemmatizer(sentence):\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    # Lemmatize:\n",
    "    mytokens = [word.lemma_.strip() for word in doc]\n",
    "\n",
    "    # Re-join\n",
    "    sentence = \" \".join(mytokens)\n",
    "\n",
    "    # Return the sentence\n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Per prima cosa, facciamo la lemmatization (su tutte le 500k righe...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>length</th>\n",
       "      <th>lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ooh shiny new commenting</td>\n",
       "      <td>16</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>ooh shiny new commenting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today parade suked bad band year battle today ...</td>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "      <td>48</td>\n",
       "      <td>today parade suke bad band year battle today k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know aabout anymore concerned everyday want bo...</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>80</td>\n",
       "      <td>know aabout anymore concerned everyday want bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roof sunset posted paul</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "      <td>roof sunset post paul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>god love nanny absolutely greatest woman earth...</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>730</td>\n",
       "      <td>god love nanny absolutely great woman earth kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526807</th>\n",
       "      <td>write injuries sand kindnesses marble french p...</td>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>write injury sand kindness marble french prove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526808</th>\n",
       "      <td>wes dad stan</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>7</td>\n",
       "      <td>wes dad stan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526809</th>\n",
       "      <td>prefer calling nice guy fact obviously carried...</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "      <td>152</td>\n",
       "      <td>prefer call nice guy fact obviously carry away...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526810</th>\n",
       "      <td>angela went othello night great noah shaved he...</td>\n",
       "      <td>17</td>\n",
       "      <td>female</td>\n",
       "      <td>77</td>\n",
       "      <td>angela go othello night great noah shave head ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526811</th>\n",
       "      <td>keeping short today busy wasting time ways onl...</td>\n",
       "      <td>33</td>\n",
       "      <td>female</td>\n",
       "      <td>196</td>\n",
       "      <td>keep short today busy waste time way online ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503900 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  age  gender  \\\n",
       "0                                ooh shiny new commenting   16  female   \n",
       "1       today parade suked bad band year battle today ...   14    male   \n",
       "2       know aabout anymore concerned everyday want bo...   24  female   \n",
       "3                                 roof sunset posted paul   24    male   \n",
       "4       god love nanny absolutely greatest woman earth...   23  female   \n",
       "...                                                   ...  ...     ...   \n",
       "526807  write injuries sand kindnesses marble french p...   34    male   \n",
       "526808                                       wes dad stan   24  female   \n",
       "526809  prefer calling nice guy fact obviously carried...   13    male   \n",
       "526810  angela went othello night great noah shaved he...   17  female   \n",
       "526811  keeping short today busy wasting time ways onl...   33  female   \n",
       "\n",
       "        length                                          lemmatize  \n",
       "0            4                           ooh shiny new commenting  \n",
       "1           48  today parade suke bad band year battle today k...  \n",
       "2           80  know aabout anymore concerned everyday want bo...  \n",
       "3            7                              roof sunset post paul  \n",
       "4          730  god love nanny absolutely great woman earth kn...  \n",
       "...        ...                                                ...  \n",
       "526807      16  write injury sand kindness marble french prove...  \n",
       "526808       7                                       wes dad stan  \n",
       "526809     152  prefer call nice guy fact obviously carry away...  \n",
       "526810      77  angela go othello night great noah shave head ...  \n",
       "526811     196  keep short today busy waste time way online ho...  \n",
       "\n",
       "[503900 rows x 5 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if this works:\n",
    "train['lemmatize'] = train['post'].apply(lemmatizer)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blogger morning hope remember things wanted link seen dallas police department web site load story says department posting pictures alleged johns convicted trouble presumption guilt picture goes web site taint jury trouble dpd turns people pictures guilty story slate offering corrections myths aabout reagan reagan great communicator owed success mainly facility television public relations reagan uniter divider reagan incorrigible optimist reagan restored faith government presidency reagan tough policy soviet union brought aabout end cold war finally john kerry decried media consolidation'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[50].post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo salviamo in un oggetto a parte\n",
    "save_object(train, 'lemmatization_2.pkl')\n",
    "\n",
    "# C'è la spunta verde? Allora chiudi il mac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding using sentence transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503900, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatization = pd.read_pickle('/Users/simonefacchiano/Desktop/Data Science/SL/Project/lemmatization_2.pkl')\n",
    "#mini_train = lemmatization[:100000]\n",
    "\n",
    "lemmatization.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "# https://www.sbert.net/docs/pretrained_models.html\n",
    "# According to this official website, this model (all-MiniLM-L6-v2) \"is 5 times faster and still offers good quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>length</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ooh shiny new commenting</td>\n",
       "      <td>16</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>ooh shiny new commenting</td>\n",
       "      <td>[-0.18770814, -0.13998552, 0.019073976, 0.0225...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today parade suked bad band year battle today ...</td>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "      <td>48</td>\n",
       "      <td>today parade suke bad band year battle today k...</td>\n",
       "      <td>[-0.11394925, 0.02999169, 0.014715457, -0.0732...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know aabout anymore concerned everyday want bo...</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>80</td>\n",
       "      <td>know aabout anymore concerned everyday want bo...</td>\n",
       "      <td>[-0.10992989, -0.04249898, 0.019761039, 0.0499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roof sunset posted paul</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "      <td>roof sunset post paul</td>\n",
       "      <td>[-0.046943568, 0.13227944, 0.02199171, 0.00461...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>god love nanny absolutely greatest woman earth...</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>730</td>\n",
       "      <td>god love nanny absolutely great woman earth kn...</td>\n",
       "      <td>[-0.03844242, -0.08146381, 0.017230963, 0.0577...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  age  gender  length  \\\n",
       "0                           ooh shiny new commenting   16  female       4   \n",
       "1  today parade suked bad band year battle today ...   14    male      48   \n",
       "2  know aabout anymore concerned everyday want bo...   24  female      80   \n",
       "3                            roof sunset posted paul   24    male       7   \n",
       "4  god love nanny absolutely greatest woman earth...   23  female     730   \n",
       "\n",
       "                                           lemmatize  \\\n",
       "0                           ooh shiny new commenting   \n",
       "1  today parade suke bad band year battle today k...   \n",
       "2  know aabout anymore concerned everyday want bo...   \n",
       "3                              roof sunset post paul   \n",
       "4  god love nanny absolutely great woman earth kn...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.18770814, -0.13998552, 0.019073976, 0.0225...  \n",
       "1  [-0.11394925, 0.02999169, 0.014715457, -0.0732...  \n",
       "2  [-0.10992989, -0.04249898, 0.019761039, 0.0499...  \n",
       "3  [-0.046943568, 0.13227944, 0.02199171, 0.00461...  \n",
       "4  [-0.03844242, -0.08146381, 0.017230963, 0.0577...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.encode('Hello world')\n",
    "mini_train = lemmatization[:100000]\n",
    "\n",
    "mini_train['embedding'] = mini_train['lemmatize'].apply(model.encode)\n",
    "mini_train.head()\n",
    "\n",
    "# 10000 righe --> 6m 19s\n",
    "# proiezione 426k righe: 4h e mezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(mini_train, 'embedding_100k_prova2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sono tante righe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = pd.read_pickle('/Users/simonefacchiano/Desktop/Data Science/SL/Project/embedding_100k.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea: e se facessimo l'embedding pezzo per pezzo?\n",
    "\n",
    "In pratica, per fare 500k righe ci metteremmo circa 6 ore... troppo.\n",
    "Ma se facessimo un pezzo alla volta? 100k righe a pranzo, 100k righe a cena ecc ecc... \n",
    "Risparmieremmo tempo ed risorse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini_train1: Sample di 500 righe\n",
    "mini_train1 = train[['post']][:500]\n",
    "\n",
    "# Lemmatization\n",
    "mini_train1['lemmatize'] = mini_train1['post'].apply(lemmatizer)\n",
    "\n",
    "# Embedding\n",
    "mini_train1['embedding'] = mini_train1['lemmatize'].apply(model.encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini_train2: Sample di 1000 righe\n",
    "mini_train2 = train[['post']][:1000]\n",
    "\n",
    "# Lemmatization\n",
    "mini_train2['lemmatize'] = mini_train2['post'].apply(lemmatizer)\n",
    "\n",
    "# Embedding\n",
    "mini_train2['embedding'] = mini_train2['lemmatize'].apply(model.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "                             ...                        \n",
       "495    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "496    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "497    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "498    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "499    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "Name: embedding, Length: 500, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A questo punto li confronto: le prime 500 righe di mini_train2 corrispondono in tutto e per tutto a mini_train1?\n",
    "\n",
    "mini_train3 = mini_train1.embedding - mini_train2.embedding\n",
    "mini_train3[:500]\n",
    "\n",
    "# Sì! Uguale in tutto e per tutto\n",
    "# Cioò significa che potremo runnare pezzo per pezzo, senza tenerci il computer impegnato per 10 ore di fila"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
